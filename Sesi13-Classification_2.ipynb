{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeOVN3PGCEwx"
   },
   "source": [
    "# Hacktiv8-PTP Python For Data Science // S.13 // Classification 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oqa9bpOJs2Yx"
   },
   "source": [
    "## Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWDGW_6t46Ac"
   },
   "source": [
    "Naive Bayes adalah teknik klasifikasi statistik berdasarkan Bayes Theorem. Ini adalah salah satu supervised learning algorithms yang paling sederhana. Naive Bayes classifier adalah algoritme yang cepat, akurat, dan andal. Naive Bayes classifier memiliki akurasi dan kecepatan tinggi pada kumpulan data besar.\n",
    "\n",
    "Naive Bayes classifier mengasumsikan bahwa efek fitur tertentu dalam kelas tidak bergantung pada fitur lainnya. Misalnya, pemohon pinjaman diloloskan atau tidak tergantung pada pendapatannya, pinjaman sebelumnya dan riwayat transaksi, usia, dan lokasi. Meskipun fitur ini saling bergantung, fitur ini masih dianggap terpisah. Asumsi ini menyederhanakan komputasi, dan itulah mengapa dianggap naive. Asumsi ini disebut class conditional independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqlTgAVHu98H"
   },
   "source": [
    "Bayes Theorem \n",
    "\n",
    "menawarkan suatu formula untuk mengehitung nilai probability dari satu event dengan memanfaatkan pengetahuan sebelumnya dari kondisi terkait; atau sering di kenal dengan istilah conditional probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVxwuOTD49Er"
   },
   "source": [
    "<img src=\"https://i.ibb.co/BfyBDR0/12-01.png\" width=\"400\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-UVTvH249mc"
   },
   "source": [
    "\n",
    "- P(h): probabilitas hipotesis h benar (terlepas dari datanya). Ini dikenal sebagai probabilitas sebelumnya dari h.\n",
    "- P(D): probabilitas data (terlepas dari hipotesis). Ini dikenal sebagai probabilitas sebelumnya.\n",
    "- P(h|D): probabilitas hipotesis h berdasarkan data D. Ini dikenal sebagai probabilitas posterior.\n",
    "- P(D|h): probabilitas data d jika hipotesis h benar. Ini dikenal sebagai probabilitas posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_-G6BppoWJc"
   },
   "source": [
    "P(B|A)  nilai dari probality event B dengan mengetahui even A sdh muncul / terjadi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_LhvKA1aneV",
    "outputId": "05fee0d0-1b3c-4360-b978-00201a4162dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1 * 0.5 ) / 0.09 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWNI8BszVqj4",
    "outputId": "c1d674b0-0f17-4134-f4b7-45ed2105f4c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.08 * 0.5)  + (0.5 * 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqFacYXfphh7"
   },
   "source": [
    "Conditional Probability adalah probabilitas kemunculan suatu event, dengan mengetahui bahwa eventa lain sudah muncul atau terjadi . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOWRWnqE5NfC"
   },
   "source": [
    "## How Naive Bayes classifier works?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYZmfZaV5RgV"
   },
   "source": [
    "Mari kita pahami cara kerja Naive Bayes melalui sebuah contoh. Diberikan contoh kondisi cuaca dan keputusan bermain olah raga. Kita perlu menghitung kemungkinan bermain olahraga. Sekarang, kita perlu mengklasifikasikan apakah pemain akan bermain atau tidak, berdasarkan kondisi cuaca.\n",
    "\n",
    "Naive Bayes classifier menghitung probabilitas suatu peristiwa dalam langkah-langkah berikut:\n",
    "\n",
    "- Langkah 1: Hitung probabilitas sebelumnya untuk label kelas yang diberikan\n",
    "- Langkah 2: Temukan probabilitas Kemungkinan dengan setiap atribut untuk setiap kelas\n",
    "- Langkah 3: Masukkan nilai ini ke dalam Rumus Bayes dan hitung probabilitas posterior.\n",
    "- Langkah 4: Lihat kelas mana yang memiliki probabilitas lebih tinggi, mengingat input milik kelas probabilitas yang lebih tinggi.\n",
    "\n",
    "Untuk menyederhanakan perhitungan probabilitas prior dan posterior kita dapat menggunakan dua tables frequency dan likelihood tables. Kedua tabel ini akan membantu kita menghitung probabilitas prior dan posterior. Frequency table berisi kemunculan label untuk semua fitur. Ada dua tabel kemungkinan. Likelihood Table 1 menunjukkan probabilitas sebelumnya dari label dan Likelihood Table 2 menunjukkan probabilitas posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1HUJTK7xVUh"
   },
   "source": [
    "<img src=\"https://i.ibb.co/LJ0McpJ/12-02.png\" width=\"700\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_L0yPGOxXAl"
   },
   "source": [
    "Sekarang misalkan kita ingin menghitung probabilitas bermain (Yes/No) saat cuaca mendung (Overcast).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fKFXiKpy_It"
   },
   "source": [
    "**Probability of playing:**\n",
    "\n",
    "P(Yes | Overcast) = P(Overcast | Yes) P(Yes) / P (Overcast)\n",
    "\n",
    "1. Calculate Prior Probabilities:\n",
    "\n",
    "  P(Overcast) = 4/14 = 0.29\n",
    "\n",
    "  P(Yes)= 9/14 = 0.64\n",
    "\n",
    "2. Calculate Posterior Probabilities:\n",
    "\n",
    "  P(Overcast |Yes) = 4/9 = 0.44\n",
    "\n",
    "3. Put Prior and Posterior probabilities in equation\n",
    "\n",
    "  P (Yes | Overcast) = 0.44 * 0.64 / 0.29 = 0.98(Higher)\n",
    "\n",
    "Similarly, you can calculate the probability of not playing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN8mCK0nzYLS"
   },
   "source": [
    "\n",
    "**Probability of not playing:**\n",
    "\n",
    "P(No | Overcast) = P(Overcast | No) P(No) / P (Overcast)\n",
    "\n",
    "1. Calculate Prior Probabilities:\n",
    "\n",
    "  P(Overcast) = 4/14 = 0.29\n",
    "\n",
    "  P(No)= 5/14 = 0.36\n",
    "\n",
    "2. Calculate Posterior Probabilities:\n",
    "\n",
    "  P(Overcast |No) = 0/9 = 0\n",
    "\n",
    "3. Put Prior and Posterior probabilities in equation\n",
    "\n",
    "  P (No | Overcast) = 0 * 0.36 / 0.29 = 0\n",
    "\n",
    "Probabilitas kelas 'Yes' lebih tinggi. Jadi kita bisa menentukan disini jika cuaca mendung maka pemain akan melakukan olah raga.\n",
    "\n",
    "Sekarang misalkan kita ingin menghitung probabilitas bermain saat cuaca mendung (Overcast), dan suhunya sedang (Mild)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5jdr3VrzkSc"
   },
   "source": [
    "**Probability of playing:**\n",
    "\n",
    "P(Play= Yes | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play= Yes)P(Play=Yes)\n",
    "\n",
    "P(Weather=Overcast, Temp=Mild | Play= Yes)= P(Overcast |Yes) P(Mild |Yes)\n",
    "\n",
    "1. Calculate Prior Probabilities: P(Yes)= 9/14 = 0.64\n",
    "\n",
    "2. Calculate Posterior Probabilities: P(Overcast |Yes) = 4/9 = 0.44 P(Mild |Yes) = 4/9 = 0.44\n",
    "\n",
    "3. Put Posterior probabilities in equation (2) P(Weather=Overcast, Temp=Mild | Play= Yes) = 0.44 * 0.44 = 0.1936(Higher)\n",
    "\n",
    "4. Put Prior and Posterior probabilities in equation (1) P(Play= Yes | Weather=Overcast, Temp=Mild) = 0.1936*0.64 = 0.124\n",
    "\n",
    "Similarly, you can calculate the probability of not playing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h5i77g4ymAs"
   },
   "source": [
    "**Probability of not playing:**\n",
    "\n",
    "P(Play= No | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play= No)P(Play=No)\n",
    "\n",
    "P(Weather=Overcast, Temp=Mild | Play= No)= P(Weather=Overcast |Play=No) P(Temp=Mild | Play=No)\n",
    "\n",
    "1. Calculate Prior Probabilities: P(No)= 5/14 = 0.36\n",
    "\n",
    "2. Calculate Posterior Probabilities: P(Weather=Overcast |Play=No) = 0/9 = 0 P(Temp=Mild | Play=No)=2/5=0.4\n",
    "\n",
    "3. Put posterior probabilities in equation (4) P(Weather=Overcast, Temp=Mild | Play= No) = 0 * 0.4= 0\n",
    "\n",
    "4. Put prior and posterior probabilities in equation (3) P(Play= No | Weather=Overcast, Temp=Mild) = 0*0.36=0\n",
    "\n",
    "Probabilitas kelas 'Yes' lebih tinggi. Jadi bisa dibilang disini kalau cuaca mendung dan suhunya sedang maka pemain akan main olahraga.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVXRZ3RSUo9D"
   },
   "source": [
    "### Naive Bayes Classifier Building in Scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OojbV8ZbCJrM"
   },
   "source": [
    "Defining Dataset\n",
    "\n",
    "Dalam contoh ini, kita dapat menggunakan kumpulan data dummy dengan tiga kolom: weather, temperature, dan play. Dua yang pertama adalah features(weather, temperature) dan yang lainnya adalah label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ou6uX2580ELf"
   },
   "outputs": [],
   "source": [
    "# Assigning features and label variables\n",
    "\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny', 'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yhc9jT1G0FfT"
   },
   "source": [
    "Encoding Features\n",
    "\n",
    "Pertama, kita perlu mengubah string menjadi angka, misalnya: 'Overcast', 'Rainy', 'Sunny' sebagai 0, 1, 2. Ini dikenal sebagai label encoding. Scikit-learn menyediakan pustaka LabelEncoder untuk mengenkode label dengan nilai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBEf5kry0HzJ",
    "outputId": "9e8d0779-2d9f-4e44-c8db-09eaf2a2b561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded=le.fit_transform(weather)\n",
    "\n",
    "print(weather_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPXfOBpl0Mwk",
    "outputId": "be4c8867-cc0c-4120-8f00-e4bdd207b48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp: [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
      "Play: [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Converting string labels into numbers\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "label=le.fit_transform(play)\n",
    "\n",
    "print(\"Temp:\",temp_encoded)\n",
    "print(\"Play:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fitFt_Fz0O9I",
    "outputId": "5c3e3aa5-89ce-4c06-de96-35a7d9c418f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1),\n",
       " (2, 1),\n",
       " (0, 1),\n",
       " (1, 2),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (2, 0),\n",
       " (1, 2),\n",
       " (2, 2),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (1, 2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinig weather and temp into single listof tuples\n",
    "\n",
    "features=list(zip(weather_encoded,temp_encoded))\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGi0TVAE0Q1a",
    "outputId": "15f2e6c6-58f4-41d0-a841-5c2e8dd7f1d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [1]\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features,label)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "print(\"Predicted Value:\", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ncJRROxUgsK"
   },
   "source": [
    "### Naive Bayes with Multiple Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tw0nfx5t0YsC"
   },
   "source": [
    "Sampai saat ini kita  telah mempelajari klasifikasi Naive Bayes dengan label biner. Sekarang kita akan belajar tentang multiple class classification di Naive Bayes. Yang dikenal sebagai multinomial Naive Bayes classification. Misalnya, jika kita ingin mengklasifikasikan artikel berita tentang teknologi, hiburan, politik, atau olahraga.\n",
    "\n",
    "Pada bagian pembuatan model, kita dapat menggunakan dataset wine yang merupakan multi-class classification yang sangat terkenal. Kumpulan data ini adalah hasil dari analisis kimiawi anggur yang ditanam di wilayah yang sama di Italia tetapi berasal dari tiga kultivar berbeda.\n",
    "\n",
    "Set data terdiri dari 13 fitur (alcohol, malic_acid, ash, alcalinity_of_ash, magnesium, total_phenols, flavanoids, nonflavanoid_phenols, proanthocyanins, color_intensity, hue, od280/od315_of_diluted_wines, proline) dan type of wine cultivar. Data ini memiliki tiga jenis anggur Class_0, Class_1, dan Class_3. Di sini kita  dapat membuat model untuk mengklasifikasikan jenis anggur.\n",
    "\n",
    "Dataset tersedia di pustaka scikit-learn.\n",
    "\n",
    "Loading Data\n",
    "\n",
    "Let's first load the required wine dataset from scikit-learn datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VE_qZX620a_u"
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSDNy1Rd0c6z",
    "outputId": "5682df31-b782-405d-8c90-417131c843bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Labels:  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# print the names of the 13 features\n",
    "print(\"Features: \", wine.feature_names)\n",
    "\n",
    "# print the label type of wine(class_0, class_1, class_2)\n",
    "print(\"Labels: \", wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXytyQfd0ekq",
    "outputId": "0db78128-ed8e-41a8-8850-0aefa59f5658"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data(feature)shape\n",
    "wine.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2N9mA6Z0gQl",
    "outputId": "a8751342-ee4d-483b-da83-938e26648dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n"
     ]
    }
   ],
   "source": [
    "# print the wine data features (top 5 records)\n",
    "print(wine.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9shQeJi0jHT",
    "outputId": "b2b24cb2-5116-411c-ade5-8f3cc332f897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# print the wine labels (0:Class_0, 1:class_2, 2:class_2)\n",
    "print(wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "JNWAVpWb0lSD"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3,random_state=109) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpXOzdrwgbSO",
    "outputId": "c8627589-1412-4dbb-c24b-ac30dce22572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.323e+01, 3.300e+00, 2.280e+00, ..., 5.600e-01, 1.510e+00,\n",
       "        6.750e+02],\n",
       "       [1.384e+01, 4.120e+00, 2.380e+00, ..., 5.700e-01, 1.640e+00,\n",
       "        4.800e+02],\n",
       "       [1.220e+01, 3.030e+00, 2.320e+00, ..., 6.600e-01, 1.830e+00,\n",
       "        5.100e+02],\n",
       "       ...,\n",
       "       [1.362e+01, 4.950e+00, 2.350e+00, ..., 9.100e-01, 2.050e+00,\n",
       "        5.500e+02],\n",
       "       [1.336e+01, 2.560e+00, 2.350e+00, ..., 7.000e-01, 2.470e+00,\n",
       "        7.800e+02],\n",
       "       [1.439e+01, 1.870e+00, 2.450e+00, ..., 1.020e+00, 3.580e+00,\n",
       "        1.290e+03]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3WiEaApb0oay"
   },
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atM_lXHf0p5f",
    "outputId": "7c30f337-fd90-457b-8f2c-df78db31a652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYFbFMKJUuYq"
   },
   "source": [
    "## Decision Tree Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE7ZqM4c0tUQ"
   },
   "source": [
    "Decision tree adalah flowchart-like tree structure di mana internal node mewakili feature(atau attribute), branch mewakili decision rule, dan setiap leaf node mewakili outcome. Node paling atas dalam pohon keputusan dikenal sebagai root node. Root node belajar untuk mempartisi berdasarkan nilai atribut. Root node mempartisi pohon secara rekursif memanggil partisi rekursif. Flowchart-like structure ini membantu kita dalam pengambilan keputusan. Visualisasinya seperti diagram flowchart yang dengan mudah meniru pemikiran tingkat manusia. Itulah mengapa decision trees mudah dipahami dan diinterpretasikan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQt2fCVU0v9k"
   },
   "source": [
    "<img src=\"https://i.ibb.co/x2NbWYM/12-03.jpg\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P9PyPI80xru"
   },
   "source": [
    "**How does the Decision Tree algorithm work?**\n",
    "\n",
    "Ide dasar di balik decision tree algorithm adalah sebagai berikut:\n",
    "\n",
    "Pilih atribut terbaik menggunakan Attribute Selection Measures (ASM) untuk membagi catatan.\n",
    "Jadikan atribut itu sebagai simpul keputusan dan pisahkan dataset menjadi subset yang lebih kecil.\n",
    "Memulai pembuatan pohon dengan mengulangi proses ini secara rekursif untuk setiap anak hingga salah satu kondisi cocok:\n",
    "Semua tupel memiliki nilai atribut yang sama.\n",
    "Tidak ada lagi atribut yang tersisa.\n",
    "Tidak ada lagi contoh.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1AS2smcaZms"
   },
   "source": [
    "**Algoritm :** \n",
    "\n",
    "- CART (Classification & Regression Tree) \n",
    "- ID3 \n",
    "- C4.5 \n",
    "- C5.0 \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KC6UQsuZEE4"
   },
   "source": [
    "**CART :** \n",
    "\n",
    "  **Gini Impurity** \n",
    "     \n",
    "  Impurity measure ( 0 dan 1 ) dimana 0 nilai yang murni sempurna sedangkan 1 nilai paling tidak murni "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Pa6miL3Zw48"
   },
   "source": [
    "- Ini adalah ukuran seberapa sering elemen yang dipilih secara acak dari himpunan akan diberi label yang salah.\n",
    "- Ini membantu untuk mengetahui simpul akar, simpul perantara dan simpul daun untuk mengembangkan pohon keputusan\n",
    "- Ini digunakan oleh algoritma CART (klasifikasi dan pohon regresi) untuk pohon klasifikasi.\n",
    "- Mencapai minimum (nol) ketika semua kasus di node jatuh ke dalam satu target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHSAir9sbq-E"
   },
   "source": [
    "$\n",
    "\\begin{align*} \n",
    "G &= 1 - \\sum_i^n P_i^2 \\\\\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw-Pf6Hmcjvz"
   },
   "source": [
    "<img src=\"https://i.ibb.co/LPWXnrM/gini-index-steps.png\" width=\"600\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgD-1gwCczjm"
   },
   "source": [
    "<img src=\"https://i.ibb.co/gMH5tpc/Gini-Impurity.png\" width=\"600\" align=\"center\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpD0epcDdSSf"
   },
   "source": [
    "Terdapat kolom : (Outlook, Humidity, Wind) ini adalah independen.  \n",
    "\n",
    "Dan untuk kolom (Play) ini adalah sebagai class / target di dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX1oEqkudw2q"
   },
   "source": [
    " ***fitur mana yang menjadi sebagai root atau intermediate node ?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7sNszoTd3Gc"
   },
   "source": [
    "Untuk menentukan node root :\n",
    "- Menemukan gini(D) untuk seluruh dataset:\n",
    "\n",
    "berapa banyak baris pada dataset : 14 \n",
    "Pada target berapa jumlah Ya dan Tidak : \n",
    "Ya : 9 \n",
    "Tidak : 5 \n",
    "\n",
    " probabilitas Ya dan Tidak dimasukkan ke dalam rumus gini\n",
    "  \n",
    "    Gini(D)= 1−(9/14)^2 - (5/14)^2\n",
    "           = 0.45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "T2GNkGhyi1FA",
    "outputId": "1cccf02d-b3e1-4f0f-c0e0-e6e0bee5c69f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D6</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D7</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D8</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D9</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D10</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D11</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D12</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D13</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D14</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Day   Outlook Humidity    Wind Play\n",
       "0    D1     Sunny     High    Weak   No\n",
       "1    D2     Sunny     High  Strong   No\n",
       "2    D3  Overcast     High    Weak  Yes\n",
       "3    D4      Rain     High    Weak  Yes\n",
       "4    D5      Rain   Normal    Weak  Yes\n",
       "5    D6      Rain   Normal  Strong   No\n",
       "6    D7  Overcast   Normal  Strong  Yes\n",
       "7    D8     Sunny     High    Weak   No\n",
       "8    D9     Sunny   Normal    Weak  Yes\n",
       "9   D10      Rain   Normal    Weak  Yes\n",
       "10  D11     Sunny   Normal  Strong  Yes\n",
       "11  D12  Overcast     High  Strong  Yes\n",
       "12  D13  Overcast   Normal    Weak  Yes\n",
       "13  D14      Rain     High  Strong   No"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "url = \"https://raw.githubusercontent.com/iketutg/my_example_ds/main/data/play_tenis.csv\"\n",
    "df_play_tenis = pd.read_csv(url) \n",
    "df_play_tenis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xS6bZAJRfcIA"
   },
   "source": [
    "Kita mulai menghitung indeks gini untuk setiap fitur (Outlook, Wind, Humidity) : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui8IQjmnfy_I"
   },
   "source": [
    "**1.  Outlook** \n",
    "\n",
    "Terdapat tiga kategori : Overcast, Sunny , Rain \n",
    "\n",
    "Fitur Outlook: Ada tiga kategori Cerah, Mendung, Hujan ada di fitur dan di bawah ini adalah jumlah kategori dalam kumpulan data.\n",
    "- Sunny : 5\n",
    "- Overcast : 4\n",
    "- Rain : 5\n",
    "\n",
    "      Gini(Play Tenis|Outlook=Sunny)\n",
    "             = 1−(2/5)^2 - (3/5)^2 \n",
    "             = 0.48\n",
    "\n",
    "      Gini(Play Tenis|Outlook=Overcast)\n",
    "             = 1−(4/4)^2 - (0/4)^2 \n",
    "             = 0\n",
    "\n",
    "      Gini(Play Tenis|Outlook=Rain)\n",
    "             = 1−(3/5)^2 - (2/5)^2 \n",
    "             = 0.48\n",
    "\n",
    "      Gini Index \n",
    "             = (5/14 * 0.48) + (4/14 * 0) + (5/14*0.48) \n",
    "             = 0.34\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGTujK-jjXgs"
   },
   "source": [
    "**2.  Wind**\n",
    "\n",
    "Terdapat tiga kategori : Strong, Weak  \n",
    "\n",
    "- Strong : 6\n",
    "- Weak : 8\n",
    "\n",
    "      Gini(Play Tenis|Wind=Strong)\n",
    "             = 1−(3/6)^2 - (3/6)^2 \n",
    "             = 0.5\n",
    "\n",
    "      Gini(Play Tenis|Wind=Weak)\n",
    "             = 1−(6/8)^2 - (2/8)^2 \n",
    "             = 0.37\n",
    "\n",
    "      Gini Index \n",
    "             = (6/14 * 0.5) + (8/14 * 0.37) \n",
    "             = 0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1N7Le8gkBMf"
   },
   "source": [
    "**3.  Humidity**\n",
    "\n",
    "Terdapat tiga kategori : High, Normal  \n",
    "\n",
    "- High : 7\n",
    "- *Normal* : 7\n",
    "\n",
    "      Gini(Play Tenis|Humidity=High)\n",
    "             = 1−(3/7)^2 - (4/7)^2 \n",
    "             = 0.48\n",
    "\n",
    "      Gini(Play Tenis|Humidity=Normal)\n",
    "             = 1−(6/7)^2 - (1/7)^2 \n",
    "             = 0.24\n",
    "\n",
    "      Gini Index \n",
    "             = (7/14 * 0.48) + (7/14 * 0.24) \n",
    "             = 0.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0CiPKRWkhnU"
   },
   "source": [
    "Menghitung Gini Gain : \n",
    "\n",
    "Gini Gain adalah perbedaan antara \"indeks Gini untuk seluruh dataset\" dan \"rata-rata indeks Gini untuk fitur individual\".\n",
    "\n",
    "- Indeks Gini dari seluruh dataset : 0.45 \n",
    "\n",
    "- Indeks gini fitur individual \n",
    "  - Outlook : 0.34 \n",
    "  - Wind : 0.36\n",
    "  - Humidity : 0.42 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibcfNAGdlwQ-"
   },
   "source": [
    "<img src=\"https://i.ibb.co/WVgqhjh/summary-gini.png\" width=\"600\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lFpmpb5lxtc"
   },
   "source": [
    "***Gini Gain Tertinggi atau Gini Index terendah harus dipilih sebagai simpul akar dari Pohon Keputusan.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmONWUlEl0RU"
   },
   "source": [
    "<img src=\"https://i.ibb.co/pj79xvb/final-Tree.png\" width=\"600\" align=\"center\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdRnhkFCmO6L"
   },
   "source": [
    "### Percobaan menggunakan Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "9pKLXs3S253T"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "kkN8wo_d3AbZ",
    "outputId": "d2ea7691-3ccd-44d0-c151-7ace795a4823"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D6</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D7</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D8</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D9</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D10</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D11</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D12</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D13</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D14</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Day   Outlook Humidity    Wind Play\n",
       "0    D1     Sunny     High    Weak   No\n",
       "1    D2     Sunny     High  Strong   No\n",
       "2    D3  Overcast     High    Weak  Yes\n",
       "3    D4      Rain     High    Weak  Yes\n",
       "4    D5      Rain   Normal    Weak  Yes\n",
       "5    D6      Rain   Normal  Strong   No\n",
       "6    D7  Overcast   Normal  Strong  Yes\n",
       "7    D8     Sunny     High    Weak   No\n",
       "8    D9     Sunny   Normal    Weak  Yes\n",
       "9   D10      Rain   Normal    Weak  Yes\n",
       "10  D11     Sunny   Normal  Strong  Yes\n",
       "11  D12  Overcast     High  Strong  Yes\n",
       "12  D13  Overcast   Normal    Weak  Yes\n",
       "13  D14      Rain     High  Strong   No"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/iketutg/my_example_ds/main/data/play_tenis.csv\"\n",
    "df_play_tenis = pd.read_csv(url) \n",
    "df_play_tenis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "aQJc85FR3Efk"
   },
   "outputs": [],
   "source": [
    "df_play_tenis.drop(columns=['Day'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_HeRj4J3GKy",
    "outputId": "a5121ca4-9b29-487e-c9af-5d5a0908c0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Outlook   14 non-null     object\n",
      " 1   Humidity  14 non-null     object\n",
      " 2   Wind      14 non-null     object\n",
      " 3   Play      14 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 576.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_play_tenis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "uWWOMQTp3GlL",
    "outputId": "05b5ae3b-8174-40e9-db71-d51354e7d1fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Humidity  Wind  Play\n",
       "0         2         0     1     0\n",
       "1         2         0     0     0\n",
       "2         0         0     1     1\n",
       "3         1         0     1     1\n",
       "4         1         1     1     1\n",
       "5         1         1     0     0\n",
       "6         0         1     0     1\n",
       "7         2         0     1     0\n",
       "8         2         1     1     1\n",
       "9         1         1     1     1\n",
       "10        2         1     0     1\n",
       "11        0         0     0     1\n",
       "12        0         1     1     1\n",
       "13        1         0     0     0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder() \n",
    "cols = list(df_play_tenis)\n",
    "for col in cols: \n",
    "    df_play_tenis[col] = le.fit_transform(df_play_tenis[col])\n",
    "df_play_tenis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WNBgKQc3nIf",
    "outputId": "122b6e5f-424f-423f-fb64-bc4040d3ed65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     0\n",
       "6     1\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    0\n",
       "Name: Play, dtype: int32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Feature \n",
    "feature = df_play_tenis.drop('Play', axis=1)\n",
    "feature_cols = list(feature)\n",
    "feature \n",
    "# Select target\n",
    "target = df_play_tenis['Play']\n",
    "target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "hFkTuSIKgtBq",
    "outputId": "2cb0e4af-a0f5-4f5c-b773-fb713cb082c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Humidity  Wind\n",
       "2         0         0     1\n",
       "10        2         1     0\n",
       "4         1         1     1\n",
       "1         2         0     0\n",
       "12        0         1     1\n",
       "0         2         0     1\n",
       "13        1         0     0\n",
       "9         1         1     1\n",
       "8         2         1     1\n",
       "11        0         0     0\n",
       "5         1         1     0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset into training set and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=1) # 80% training and 20% test\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "jw7ulQj-l3x3",
    "outputId": "7211bb96-ae4d-4bac-bbe4-2c1ca813bfa1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outlook  Humidity  Wind\n",
       "3        1         0     1\n",
       "7        2         0     1\n",
       "6        0         1     0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcGFGFYz332g",
    "outputId": "98b06b1b-966d-4858-906b-0c01a4e48b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#clf = clf.fit(feature,target)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "#y_pred = clf.predict(feature)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "5g6IY5KM4CST",
    "outputId": "9baabb06-c5c2-494b-fa81-2f29aef2dc99"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ce1bbbe23536>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "import sklearn.tree as tree\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, \n",
    " out_file=dot_data, \n",
    " class_names=['0','1'], # the target names.\n",
    " feature_names=feature_cols, # the feature names.\n",
    " filled=True, # Whether to fill in the boxes with colours.\n",
    " rounded=True, # Whether to round the corners of the boxes.\n",
    " special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OiMaIur3mWf"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJgcOGwUgPFS"
   },
   "outputs": [],
   "source": [
    "tree = decision_tree_algorithm(X_train, ml_task=\"classification\", max_depth=10)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9_07ohh3liQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sndyz0dJU4q8"
   },
   "source": [
    "### Decision Tree Classifier Building in Scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuF80Zyl02CD"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nPMnGq-04pH"
   },
   "outputs": [],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "# load dataset\n",
    "pima = pd.read_csv(\"https://raw.githubusercontent.com/ardhiraka/PFDS_sources/master/diabetes.csv\", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "BvVAujat06ls",
    "outputId": "e6ba3a1f-e0d3-4100-878a-6513843e212e"
   },
   "outputs": [],
   "source": [
    "pima.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGRVFn6x5ad_"
   },
   "source": [
    "Feature Selection\n",
    "\n",
    "Di sini, kita perlu membagi kolom yang diberikan menjadi dua jenis variabel dependen (atau variabel target) dan variabel independen (atau variabel fitur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i83ovlBJ09yA",
    "outputId": "9bd06736-d737-4bd2-d96a-4df33e6e1dcf"
   },
   "outputs": [],
   "source": [
    "pima.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2_Ax-FR1CkH"
   },
   "outputs": [],
   "source": [
    "numer = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree', 'label']\n",
    "\n",
    "for col in numer: # coerce for missing values\n",
    "    pima[col] = pd.to_numeric(pima[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHE5igdd1EBu"
   },
   "outputs": [],
   "source": [
    "pima.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKvNJGXi1GhT"
   },
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8Q6MkNs5HIS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ0EHP-71IdC"
   },
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQLfB26c1Kuf"
   },
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMPEOMs01NON",
    "outputId": "3e46da61-d474-4db1-e251-ea11acfb5af3"
   },
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMJGJ45408tn"
   },
   "source": [
    "Feature Selection\n",
    "\n",
    "Di sini, kita perlu membagi kolom yang diberikan menjadi dua jenis variabel dependen (atau variabel target) dan variabel independen (atau variabel fitur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK4SzDRk1R7h"
   },
   "source": [
    "### Visualizing Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Roq-C9bw1Uvp"
   },
   "source": [
    "Kita bisa menggunakan fungsi export_graphviz Scikit-learn untuk menampilkan tree dalam notebook Jupyter. Untuk plotting tree, kita juga perlu menginstal graphviz dan pydotplus.\n",
    "\n",
    "pip install graphviz\n",
    "\n",
    "pip install pydotplus\n",
    "\n",
    "Fungsi export_graphviz mengubah decision tree classifier menjadi dot file dan pydotplus mengonversi file dot ini ke png atau bentuk yang dapat ditampilkan di Jupyter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmXAe3Ck1Wu7"
   },
   "source": [
    "!conda install python-graphviz -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwmFxx5n1ZWG",
    "outputId": "26d2b08b-bfba-4846-9755-010a0b0eb0d5"
   },
   "outputs": [],
   "source": [
    "!pip install pydotplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9r5_u6t-1js3",
    "outputId": "ca0e5758-0816-4c73-9894-d851841f5421"
   },
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, \n",
    " out_file=dot_data, \n",
    " class_names=['0','1'], # the target names.\n",
    " feature_names=feature_cols, # the feature names.\n",
    " filled=True, # Whether to fill in the boxes with colours.\n",
    " rounded=True, # Whether to round the corners of the boxes.\n",
    " special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C9fkgAW1nAd"
   },
   "source": [
    "### Optimizing Decision Tree Performance\n",
    "\n",
    "- kriteria : opsional (default=”gini”) atau Pilih ukuran pemilihan atribut: Parameter ini memungkinkan kita untuk menggunakan ukuran pemilihan atribut yang berbeda-beda. Kriteria yang didukung adalah “gini” untuk indeks Gini dan “entropi” untuk perolehan informasi.\n",
    "\n",
    "- splitter : string, optional (default=”best”) atau Split Strategy: Parameter ini memungkinkan kita untuk memilih strategi split. Strategi yang didukung adalah “terbaik” untuk memilih split terbaik dan “random” untuk memilih split acak terbaik.\n",
    "\n",
    "- max_depth : int atau None, optional (default=None) atau Maximum Depth of a Tree: Kedalaman maksimum pohon. Jika Tidak Ada, maka node diperluas hingga semua daun berisi kurang dari sampel min_samples_split. Nilai kedalaman maksimum yang lebih tinggi menyebabkan overfitting, dan nilai yang lebih rendah menyebabkan underfitting (Sumber).\n",
    "\n",
    "Dalam Scikit-learn, pengoptimalan decision tree classifier dilakukan hanya dengan pre-pruning. Maximum depth pohon dapat digunakan sebagai variabel kontrol untuk pre-pruning. Dalam contoh berikut, kita dapat memplot decision tree pada data yang sama dengan max_depth = 3. Selain parameter pre-pruning, kita  juga dapat mencoba ukuran pemilihan atribut lain seperti entropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DG65t1c1zXU",
    "outputId": "350895b2-59eb-412e-b374-4c7a0279eba3"
   },
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "wpZt2UMN12sz",
    "outputId": "2d46d3fe-77b8-4f8f-b926-1ce10b8bc53b"
   },
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, \n",
    " out_file=dot_data, \n",
    " class_names=['0','1'], # the target names.\n",
    " feature_names=feature_cols, # the feature names.\n",
    " filled=True, # Whether to fill in the boxes with colours.\n",
    " rounded=True, # Whether to round the corners of the boxes.\n",
    " special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9h67OnwYsiuF"
   },
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaDZNp4ceqDI"
   },
   "source": [
    "<img src=\"https://i.ibb.co/5T4GGL3/random-forest.png\" width=\"650\" align=\"center\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrleVD0BxVRy"
   },
   "source": [
    "Random Forest secara teknis adalah ensemble method (berdasarkan pendekatan divide-and-conquer) dari decision trees yang dihasilkan pada dataset yang dipisahkan secara acak. Kumpulan decision tree classifiers ini juga dikenal sebagai forest. Decision trees individu dihasilkan menggunakan indikator pemilihan atribut seperti information gain, gain ratio, dan Gini index untuk setiap atribut. Setiap pohon bergantung pada sampel acak yang independen. Dalam masalah klasifikasi, setiap pohon memilih dan kelas paling populer dipilih sebagai hasil akhir. Dalam kasus regresi, rata-rata dari semua keluaran pohon dianggap sebagai hasil akhir. Ini lebih sederhana dan lebih kuat dibandingkan dengan algoritma klasifikasi non-linier lainnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2KIUFlzmnpU"
   },
   "source": [
    "<img src=\"https://i.ibb.co/9GvPsRD/Screen-Shot-2021-10-12-at-3-02-29-PM.png\" width=\"650\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew-jZ77anHYs"
   },
   "source": [
    "<img src=\"https://i.ibb.co/KzYPwzz/Screen-Shot-2021-10-12-at-3-15-40-PM.png\" width=\"650\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OC47iGpKnNYu"
   },
   "source": [
    "<img src=\"https://i.ibb.co/jGWfzn7/Screen-Shot-2021-10-12-at-3-24-09-PM.png\" width=\"650\" align=\"center\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtqRoEv21-O3"
   },
   "source": [
    "### How does the algorithm work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oh1o2XF32AyO"
   },
   "source": [
    "Random forest bekerja dalam 4 tahap:\n",
    "\n",
    "1. Pilih sampel acak dari kumpulan data yang diberikan.\n",
    "2. Buatlah pohon keputusan untuk setiap sampel dan dapatkan hasil prediksi dari setiap pohon keputusan.\n",
    "3. Lakukan voting untuk setiap hasil prediksi.\n",
    "4. Pilih hasil prediksi dengan suara terbanyak sebagai prediksi akhir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nuBCF_b2Cjq"
   },
   "source": [
    "<img src=\"https://i.ibb.co/Tc1Fsmh/12-04.png\" width=\"600\" align=\"center\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK9NFVaa2DlS"
   },
   "source": [
    "### Finding important features\n",
    "\n",
    "Random forests juga menawarkan indikator feature selection yang baik. Scikit-learn menyediakan variabel tambahan dengan model tersebut, yang menunjukkan importance relatif atau kontribusi setiap fitur dalam prediksi. Secara otomatis menghitung skor relevansi setiap fitur dalam fase training . Kemudian menurunkan relevansi sehingga jumlah semua skor adalah 1.\n",
    "\n",
    "Skor ini akan membantu kita memilih fitur yang paling penting dan menghapus fitur yang paling tidak penting untuk pembuatan model.\n",
    "\n",
    "Random forests menggunakan gini importance atau mean decrease in impurity (MDI) untuk menghitung tingkat importance setiap fitur. Gini importance juga dikenal sebagai total decrease dalam node impurity. Ini adalah seberapa besar kecocokan atau akurasi model menurun saat kita menghapus variabel. Semakin besar penurunannya, semakin signifikan variabel tersebut. Di sini, mean decrease adalah parameter signifikan untuk pemilihan variabel. Gini index dapat menggambarkan kekuatan penjelas variabel secara keseluruhan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9htFzW82Jpp"
   },
   "source": [
    "### Random Forests vs Decision Trees\n",
    "\n",
    "- Random forests adalah kumpulan dari beberapa decision trees.\n",
    "- Deep decision trees mungkin mengalami overfitting, tetapi random forests mencegah overfitting dengan membuat trees pada random subsets.\n",
    "- Decision trees secara komputasi lebih cepat.\n",
    "- Random forests sulit untuk diinterpretasikan, sedangkan decision tree mudah diinterpretasikan dan dapat diubah menjadi rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FeInLCs2TZu"
   },
   "source": [
    "### Building a Classifier using Scikit-learn\n",
    "\n",
    "Kita akan membuat model pada kumpulan data iris flower, yang merupakan kumpulan klasifikasi yang sangat terkenal. Terdiri dari sepal length, sepal width, petal length, petal width, dan jenis bunga. Ada tiga spesies atau kelas: setosa, versicolor, dan virginia. Kita akan membangun model untuk mengklasifikasikan jenis bunga. Dataset tersedia di pustaka scikit-learn atau kita dapat mengunduhnya dari Repositori Machine Learning UCI.\n",
    "\n",
    "Mulailah dengan mengimpor pustaka kumpulan data dari scikit-learn, dan muat kumpulan data iris dengan load_iris()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqk6ofOx2YyA",
    "outputId": "bbb9f16f-3e18-4efc-d1bd-60095f1da20e"
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets \n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_ywgueu2a8a"
   },
   "source": [
    "Kita dapat mencetak target dan feature , untuk memastikan kita memiliki dataset yang tepat, seperti:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWqkVhtM2cfG",
    "outputId": "d1d36763-db75-49d7-bc9f-8faef3fd6a07"
   },
   "outputs": [],
   "source": [
    "# print the label species(setosa, versicolor,virginica)\n",
    "print(iris.target_names) \n",
    "\n",
    "# print the names of the four features\n",
    "print(iris.feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSJYM_cm2hX4"
   },
   "source": [
    "Ada baiknya untuk selalu menjelajahi data kita sedikit, sehingga kita tahu apa yang sedang kita kerjakan. Di sini, kita dapat melihat lima baris pertama kumpulan data dicetak, serta variabel target untuk seluruh kumpulan data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud75JAp72idA",
    "outputId": "867c6429-0c22-4cfe-d5e6-64aa4d761a85"
   },
   "outputs": [],
   "source": [
    "# print the iris data (top 5 records)\n",
    "print(iris.data[0:5]) \n",
    "\n",
    "# print the iris labels (0:setosa, 1:versicolor, 2:virginica)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2xs5VyO2kxh"
   },
   "source": [
    "Di sini, kita dapat membuat DataFrame dari dataset iris dengan cara berikut.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "F83eKs-P2neY",
    "outputId": "0945fb73-9d1e-4da8-f7aa-05d90f71c39e"
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame of given iris dataset.\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.DataFrame({    \n",
    "    'sepal length':iris.data[:,0],    \n",
    "    'sepal width':iris.data[:,1],    \n",
    "    'petal length':iris.data[:,2],    \n",
    "    'petal width':iris.data[:,3],    \n",
    "    'species':iris.target \n",
    "}) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbbNgkVs2piY"
   },
   "source": [
    "Pertama, kita pisahkan kolom menjadi variabel dependen dan independen (atau features dan labels). Kemudian kita membagi variabel tersebut menjadi training dan test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXUAoX-z2q-C"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=data['species']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TE9MPSY2tD3"
   },
   "source": [
    "Setelah dipisahkan, kita akan melatih model pada set training dan melakukan prediksi pada set test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-wmNO7a2urv"
   },
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    " \n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train) \n",
    "\n",
    "y_pred=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAZp8oWC2xGX"
   },
   "source": [
    "Setelah training, periksa accuracy menggunakan nilai actual dan predicted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hV4w6CK2zC_",
    "outputId": "8af485bb-8edb-4c04-f0de-c91cbcf4e362"
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JHmksNV21UF"
   },
   "source": [
    "Kita juga dapat membuat prediksi untuk satu item, misalnya:\n",
    "\n",
    "sepal length = 3\n",
    "sepal width = 5\n",
    "petal length = 4\n",
    "petal width = 2\n",
    "Sekarang kita  bisa memprediksi jenis bunganya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dedFtHyb23_t",
    "outputId": "a3b12529-c825-487d-f246-7812906af13f"
   },
   "outputs": [],
   "source": [
    "clf.predict([[3, 5, 4, 2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIwWl28q3BKO"
   },
   "source": [
    "### Finding Important Features in Scikit-learn\n",
    "Di sini, kita dapat menemukan fitur penting atau memilih fitur dalam dataset IRIS. Dalam scikit-learn, kita dapat melakukan tugas ini dalam langkah-langkah berikut:\n",
    "\n",
    "First, you need to create a random forests model.\n",
    "Second, use the feature importance variable to see feature importance scores.\n",
    "Third, visualize these scores using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgv3SCwH3Do0",
    "outputId": "3df08250-2027-4c4f-c1b2-0358cfa1e423"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71h6d9Ac3HRU",
    "outputId": "262cfdd0-0aee-457c-9192-3032ad157d22"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False) \n",
    "\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUe-dLgh3J1-"
   },
   "source": [
    "Kita juga dapat memvisualisasikan feature importance. Visualisasi mudah dipahami dan diinterpretasikan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "QvVGQCqM3K3d",
    "outputId": "8b0a31c0-287a-4b05-b2a3-ffff9c74fe9b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ek-wY9FG28oG"
   },
   "source": [
    "### Generating the Model on Selected Features\n",
    "\n",
    "Di sini, kita dapat menghapus fitur \"sepal width\" karena tingkat kepentingannya sangat rendah, dan memilih 3 fitur lainnya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDkiQIFm3S1H"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "##from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into features and labels\n",
    "X=data[['petal length', 'petal width','sepal length']]\n",
    "y=data['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtSgN3qy3WeY"
   },
   "source": [
    "Setelah dipisah, kita akan membuat model pada training set features yang dipilih, melakukan prediksi pada test set features yang dipilih, dan membandingkan nilai aktual dan nilai prediksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMr-HckY3Ybl",
    "outputId": "88adbc11-3937-4faa-b690-42ba3bb5c64e"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train) \n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test) \n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXhYJltZ3a8P"
   },
   "source": [
    "Kita dapat melihat bahwa setelah menghapus fitur yang paling tidak penting (sepal length), keakuratannya meningkat. Ini karena kita  menghapus data dan noise yang menyesatkan, sehingga meningkatkan akurasi. Jumlah fitur yang lebih sedikit juga mengurangi training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t13-jOmsq_q"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUjGW4zA3dlf"
   },
   "source": [
    "Secara umum, Support Vector Machines dianggap sebagai classification approach, tetapi dapat digunakan di kedua jenis masalah klasifikasi dan regresi. \n",
    "\n",
    "SVM dapat dengan mudah menangani beberapa variabel kontinu dan kategorikal. \n",
    "\n",
    "SVM membangun hyperplane  dalam multidimensional space untuk memisahkan kelas yang berbeda. \n",
    "\n",
    "SVM menghasilkan hyperplane optimal secara berulang, yang digunakan untuk meminimalkan kesalahan. \n",
    "\n",
    "Ide inti dari SVM adalah menemukan maximum marginal hyperplane(MMH) yang paling baik membagi dataset menjadi beberapa kelas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KViff5iH3eTd"
   },
   "source": [
    "<img src=\"https://i.ibb.co/NSRy7ph/12-05.png\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHf6Lcrt3gSI"
   },
   "source": [
    "**Support Vectors**\n",
    "Support vectors adalah data points, yang paling dekat dengan hyperplane. Titik-titik ini akan menentukan garis pemisah dengan lebih baik dengan menghitung margin.\n",
    "\n",
    "**Hyperplane**\n",
    "Hyperplane adalah decision plane yang memisahkan antara sekumpulan objek yang memiliki kelas yang berbeda.\n",
    "\n",
    "**Margin**\n",
    "Margin adalah celah antara dua garis pada poin kelas terdekat. Margin dihitung sebagai jarak tegak lurus dari garis untuk mendukung vektor atau titik terdekat. Jika margin lebih besar di antara kelas, maka itu dianggap sebagai margin yang baik, margin yang lebih kecil adalah margin yang buruk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1atzm7uV3mrl"
   },
   "source": [
    "### How does SVM work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEWNy3z3pal"
   },
   "source": [
    "Tujuan utamanya adalah untuk memisahkan kumpulan data yang diberikan dengan cara terbaik. Jarak antara salah satu titik terdekat dikenal sebagai margin. Tujuannya adalah untuk memilih hyperplane dengan kemungkinan margin maksimum antara support vectors dalam dataset yang diberikan. SVM mencari hyperplane marginal maksimum dalam langkah-langkah berikut:\n",
    "\n",
    "1. Hasilkan hyperplane yang memisahkan kelas dengan cara terbaik. Gambar sisi kiri menunjukkan tiga hyperplanes hitam, biru dan oranye. Di sini, biru dan oranye memiliki kesalahan klasifikasi yang lebih tinggi, tetapi hitam memisahkan dua kelas dengan benar.\n",
    "\n",
    "2. Pilih hyperplane kanan dengan segregasi maksimum dari salah satu titik data terdekat seperti yang ditunjukkan pada gambar sebelah kanan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2mCaJdy3tio"
   },
   "source": [
    "<img src=\"https://i.ibb.co/bJYd6fY/12-06.png\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgVbzB5S3vn7"
   },
   "source": [
    "### Dealing with non-linear and inseparable planes\n",
    "Beberapa masalah tidak dapat diselesaikan menggunakan linear hyperplane, seperti yang ditunjukkan pada gambar di bawah ini (sisi kiri).\n",
    "\n",
    "Dalam situasi seperti itu, SVM menggunakan kernel untuk mengubah input space ke ruang dimensi yang lebih tinggi seperti yang ditunjukkan di sebelah kanan. Titik data diplot pada sumbu x dan sumbu z (Z adalah jumlah kuadrat dari x dan y: z=x^2=y^2). Sekarang kita dapat dengan mudah memisahkan titik-titik ini menggunakan pemisahan linier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqVwlrCK3y1d"
   },
   "source": [
    "<img src=\"https://i.ibb.co/jh36BW4/12-07.png\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXdSqI6g30pg"
   },
   "source": [
    "### SVM Kernels\n",
    "Algoritma SVM diimplementasikan dalam praktiknya menggunakan kernel. Kernel mengubah input data space menjadi bentuk yang diperlukan. SVM menggunakan teknik yang disebut kernel. Di sini, kernel mengambil low-dimensional input space dan mengubahnya menjadi ruang berdimensi lebih tinggi. Dengan kata lain, kita dapat mengatakan bahwa SVM mengubah nonseparable problem menjadi separable problems dengan menambahkan lebih banyak dimensi padanya. SVM paling berguna dalam masalah pemisahan non-linier. Kernel membantu kita membuat pengklasifikasi yang lebih akurat.\n",
    "\n",
    "Linear Kernel linear kernel dapat digunakan sebagai dot product pada dua pengamatan yang diberikan. Hasil perkalian antara dua vektor adalah hasil perkalian setiap pasang nilai masukan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1U_X6cD35Cg"
   },
   "source": [
    "`K(x, xi) = sum(x * xi)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx3QTXK637mf"
   },
   "source": [
    "- Polynomial Kernel Kernel polinomial adalah bentuk kernel linier yang lebih umum. Kernel polinomial dapat membedakan ruang masukan lengkung atau nonlinier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dhs2ca83-A2"
   },
   "source": [
    "`K(x,xi) = 1 + sum(x * xi)^d`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1hdMXMd4A8u"
   },
   "source": [
    "Dimana d adalah derajat polinomial. d = 1 mirip dengan linear transformation. Degree perlu ditentukan secara manual dalam learning algorithm.\n",
    "\n",
    "Radial Basis Function Kernel Radial basis function kernel adalah fungsi kernel populer yang biasa digunakan dalam support vector machine classification. RBF dapat memetakan ruang masukan dalam ruang dimensi tak terhingga.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwUrRg_E4CjV"
   },
   "source": [
    "`K(x,xi) = exp(-gamma * sum((x – xi^2))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSdCcTVk4Fl1"
   },
   "source": [
    "Di sini gamma adalah parameter, yang berkisar dari 0 sampai 1. Nilai gamma yang lebih tinggi akan sangat cocok dengan training dataset, yang menyebabkan over-fitting. Gamma = 0.1 dianggap sebagai nilai default yang baik. Nilai gamma perlu ditentukan secara manual dalam learning algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsZ-zoOw4HVn"
   },
   "source": [
    "### Classifier Building in Scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXe6y05K4JHD"
   },
   "source": [
    "Sampai saat ini, kita telah mempelajari tentang latar belakang teori SVM. Sekarang kita akan belajar tentang implementasinya dengan Python menggunakan scikit-learn.\n",
    "\n",
    "Dalam membuat model, kita dapat menggunakan cancer dataset, yang merupakan multi-class classification problem yang sangat terkenal. Dataset ini dihitung dari gambar digital dari fine needle aspirate (FNA) dari massa payudara. Mereka menggambarkan karakteristik inti sel yang ada dalam gambar.\n",
    "\n",
    "Dataset terdiri dari 30 fitur \n",
    "\n",
    "(mean radius, mean texture, mean perimeter, mean area, mean smoothness, mean compactness, mean concavity, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst radius, worst texture, worst perimeter, worst area, worst smoothness, worst compactness, worst concavity, worst concave points, worst symmetry, and worst fractal dimension) dan target (jenis kanker).\n",
    "\n",
    "Data ini memiliki dua jenis kelas kanker: malignant (berbahaya) dan benign(tidak berbahaya). Di sini, kita  dapat membuat model untuk mengelompokkan jenis kanker. Dataset tersedia di pustaka scikit-learn atau kita juga dapat mengunduhnya dari UCI Machine Learning Library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtgDVlMm4Mur"
   },
   "source": [
    "### Loading Data\n",
    "Mari muat dulu kumpulan data yang diperlukan yang akan kita gunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SprI5IYJ4O-R"
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets \n",
    "\n",
    "#Load dataset\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9viadOVj4RB4"
   },
   "source": [
    "### Exploring Data\n",
    "Setelah kita memuat set data, kita  mungkin ingin tahu lebih banyak tentangnya. Kita dapat memeriksa fitur dan nama target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kdV686c4VPX",
    "outputId": "d99845cd-f751-441b-daf4-5055186571d0"
   },
   "outputs": [],
   "source": [
    "# print the names of the 13 features\n",
    "print(\"Features: \", cancer.feature_names) \n",
    "\n",
    "# print the label type of cancer('malignant' 'benign')\n",
    "print(\"Labels: \", cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC9JWFzU4XR3"
   },
   "source": [
    "Mari kita jelajahi lebih banyak lagi. Kita juga dapat memeriksa bentuk kumpulan data menggunakan shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrDN3p7AxVe0",
    "outputId": "cf19e4fb-52c7-43e9-d730-7efeb4d88b7a"
   },
   "outputs": [],
   "source": [
    "# print data(feature)shape\n",
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3jWWfVC4bWu"
   },
   "source": [
    "Mari kita periksa 5 record teratas dari set fitur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_Zi3eSrUjx6",
    "outputId": "40733225-73b2-408d-f0fe-1b429811ce9c"
   },
   "outputs": [],
   "source": [
    "# print the cancer data features (top 5 records)\n",
    "print(cancer.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1PTTeaw4kub",
    "outputId": "4177bf65-61f9-4147-a102-53568acdd71e"
   },
   "outputs": [],
   "source": [
    "# Mari kita lihat set target.\n",
    "\n",
    "\n",
    "# print the cancer labels (0:malignant, 1:benign)\n",
    "print(cancer.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZ6uVK-v4oYm"
   },
   "source": [
    "### Splitting Data\n",
    "\n",
    "Untuk memahami performa model, membagi set data menjadi training set dan test set adalah strategi yang baik.\n",
    "\n",
    "Pisahkan kumpulan data dengan menggunakan fungsi train_test_split(). Kita harus meneruskan 3 parameter features, target, and test_set size. Selain itu, kita dapat menggunakan random_state untuk memilih record secara acak.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Lwq1WE-4nPZ"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tt8_gNVw4uJl"
   },
   "source": [
    "### Generating Model\n",
    "\n",
    "Mari kita membangun support vector machine model. Pertama, impor modul SVM dan buat objek support vector classifier dengan meneruskan argumen kernel sebagai kernel linier dalam fungsi SVC().\n",
    "\n",
    "Kemudian, training model kita di train set menggunakanfit() dan lakukan prediksi pada set test menggunakan predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luKiTGtk4teX"
   },
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm \n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIfHr_ow4zWB"
   },
   "source": [
    "### Evaluating the Model\n",
    "Mari kita perkirakan seberapa akurat pengklasifikasi atau model dapat memprediksi kanker payudara pasien.\n",
    "\n",
    "Akurasi dapat dihitung dengan membandingkan nilai set test aktual dan nilai prediksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7gXO_DdT4ynr",
    "outputId": "241f118c-c1ae-4684-ec7f-f622cab9abc9"
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics \n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fETaMJ4r45RV"
   },
   "source": [
    "Kita  mendapat tingkat klasifikasi 96.49%, dianggap sebagai akurasi yang sangat baik.\n",
    "\n",
    "Untuk evaluasi lebih lanjut, kita juga dapat memeriksa precision dan recall model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQbdPoT743cx",
    "outputId": "4ad6554e-988b-483b-8b5b-16485f2fa853"
   },
   "outputs": [],
   "source": [
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred)) \n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVcwC-UR48mF"
   },
   "source": [
    "Kita mendapat precision 98% dan recall 96%, yang dianggap sebagai nilai yang sangat baik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlGlXNzUV2MP"
   },
   "source": [
    "\n",
    "## **Exercise: Multiple Algorithm on Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnFWVg6b47mB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MPbf_P45Bzm",
    "outputId": "97dbcbd9-1522-4fd9-9492-387e91a4d457"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/ardhiraka/PFDS_sources/master/Final_Dataset/train.csv')\n",
    "train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "FQ12486B5EjH",
    "outputId": "d8042219-6eb5-41fe-9401-c1ae1c8aff39"
   },
   "outputs": [],
   "source": [
    "train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Go09Fd535GBo",
    "outputId": "869aaa63-c8dc-46c0-b5ee-a68878904190"
   },
   "outputs": [],
   "source": [
    "print(\"Train Data:\")\n",
    "print(train.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRN7mruv5HkG",
    "outputId": "b8c31243-80ff-40df-e24a-ad066c0ad0ce"
   },
   "outputs": [],
   "source": [
    "train.fillna(train.mean(),inplace=True) \n",
    "train.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TZVNlUV5JXv",
    "outputId": "4ca8e6c4-4c79-4253-a52a-7474b153ca13"
   },
   "outputs": [],
   "source": [
    "train.Gender.fillna(train.Gender.mode()[0],inplace=True)\n",
    "train.Married.fillna(train.Married.mode()[0],inplace=True)\n",
    "train.Dependents.fillna(train.Dependents.mode()[0],inplace=True) \n",
    "train.Self_Employed.fillna(train.Self_Employed.mode()[0],inplace=True)  \n",
    "train.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4fU0-WG5KuC"
   },
   "outputs": [],
   "source": [
    "train.Loan_Amount_Term=np.log(train.Loan_Amount_Term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWZnPmDG5MSe"
   },
   "outputs": [],
   "source": [
    "X=train.drop('Loan_Status',1)\n",
    "y=train.Loan_Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xhq39dB5NXG"
   },
   "outputs": [],
   "source": [
    "X=pd.get_dummies(X)\n",
    "train=pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "KByXI1GQ5O0e",
    "outputId": "2c889c40-d3fb-4f6d-c2b0-1b71a4fc3514"
   },
   "outputs": [],
   "source": [
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N80Ua2385RHW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INDjRvsL5TIn",
    "outputId": "aac6c2fa-a260-46e0-fab9-01e10e4b3ff9"
   },
   "outputs": [],
   "source": [
    "#(a)LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymOlD0Lu5YTk"
   },
   "outputs": [],
   "source": [
    "pred_cv=model.predict(x_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93Z24JPs5aHO",
    "outputId": "10a59b4f-509c-4477-ced2-b9d4be753009"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(accuracy_score(y_cv,pred_cv))\n",
    "matrix=confusion_matrix(y_cv,pred_cv)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iawI-EeU5cGN",
    "outputId": "2e53b38b-ccb6-420f-ea7a-4092bb513904"
   },
   "outputs": [],
   "source": [
    "#(b)DECISION TREE ALGORITHM\n",
    "\n",
    "from sklearn import tree\n",
    "dt=tree.DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWzM120R5fNa"
   },
   "outputs": [],
   "source": [
    "pred_cv1=dt.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoRBYmBG5gcl",
    "outputId": "a66b95db-baae-4653-b30a-d575c200547c"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_cv,pred_cv1))\n",
    "matrix1=confusion_matrix(y_cv,pred_cv1)\n",
    "print(matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCNOTCV65ibq",
    "outputId": "76d79191-fbf2-4f05-c477-5c9f345cb831"
   },
   "outputs": [],
   "source": [
    "#(c)RANDOM FOREST ALGORITHM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_P5KjT2j5l5s"
   },
   "outputs": [],
   "source": [
    "pred_cv2=rf.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdQvoOou5nKq",
    "outputId": "687e67b1-c9e3-422e-ba46-17ca55a98ead"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_cv,pred_cv2))\n",
    "matrix2=confusion_matrix(y_cv,pred_cv2)\n",
    "print(matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4YUmdDg5plf",
    "outputId": "0f891bd9-c6fb-40ec-bfcb-94dd687adaed"
   },
   "outputs": [],
   "source": [
    "#(d)SUPPORT VECTOR MACHINE (SVM) ALGORITHM\n",
    "from sklearn import svm\n",
    "svm_model=svm.SVC()\n",
    "svm_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOSTdAvH5zZb"
   },
   "outputs": [],
   "source": [
    "pred_cv3=svm_model.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9nWjAQh50j2",
    "outputId": "09c9c8ee-9c9a-4b7b-c9ec-c9d0e7a0347c"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_cv,pred_cv3))\n",
    "matrix3=confusion_matrix(y_cv,pred_cv3)\n",
    "print(matrix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9OxQpdk521P",
    "outputId": "e55be431-7d19-46a1-ea56-a160329f8314"
   },
   "outputs": [],
   "source": [
    "#(e)NAIVE BAYES ALGORITHM\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "\n",
    "pred_cv4=nb.predict(x_cv)\n",
    "\n",
    "print(accuracy_score(y_cv,pred_cv4))\n",
    "matrix4=confusion_matrix(y_cv,pred_cv4)\n",
    "print(matrix4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2Un4y4i55Au",
    "outputId": "119e6a9f-b818-447d-b5f9-16b59da07afa"
   },
   "outputs": [],
   "source": [
    "#(f)K-NEAREST NEIGHBOR(kNN) ALGORITHM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNN=KNeighborsClassifier()\n",
    "kNN.fit(x_train,y_train)\n",
    "\n",
    "pred_cv5=kNN.predict(x_cv)\n",
    "\n",
    "print(accuracy_score(y_cv,pred_cv5))\n",
    "matrix5=confusion_matrix(y_cv,pred_cv5)\n",
    "print(matrix5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfkaGwVs57YR",
    "outputId": "f00006c7-806a-417a-ca11-3145a090d57a"
   },
   "outputs": [],
   "source": [
    "print(\"Logistic Regression:\", accuracy_score(y_cv,pred_cv))\n",
    "print(\"Decision Tree:\", accuracy_score(y_cv,pred_cv1))\n",
    "print(\"Random Forest:\", accuracy_score(y_cv,pred_cv2))\n",
    "print(\"SVM:\", accuracy_score(y_cv,pred_cv3))\n",
    "print(\"Naive Bayes:\", accuracy_score(y_cv,pred_cv4))\n",
    "print(\"KNN:\", accuracy_score(y_cv,pred_cv5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7WuaeuY59QS"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Write test results in csv file\n",
    "predictions=pd.DataFrame(pred_cv2, columns=['predictions']).to_csv('H8_NB_Credit_Predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W25Q5eOTrhK"
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVhou5oeTtb1"
   },
   "source": [
    "Utilitas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbK82La2V1MY"
   },
   "source": [
    "## Decestion Tree From Scratch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omQLHLGpV8IU"
   },
   "outputs": [],
   "source": [
    "# 1. Decision Tree helper functions\n",
    "# 1.1 Data pure?\n",
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "# 1.2 Create Leaf\n",
    "def create_leaf(data, ml_task):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    if ml_task == \"regression\":\n",
    "        leaf = np.mean(label_column)\n",
    "        \n",
    "    # classfication    \n",
    "    else:\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "        index = counts_unique_classes.argmax()\n",
    "        leaf = unique_classes[index]\n",
    "    \n",
    "    return leaf\n",
    "\n",
    "\n",
    "# 1.3 Determine potential splits\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1): # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "# 1.4 Determine Best Split\n",
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_mse(data):\n",
    "    actual_values = data[:, -1]\n",
    "    if len(actual_values) == 0:   # empty data\n",
    "        mse = 0\n",
    "        \n",
    "    else:\n",
    "        prediction = np.mean(actual_values)\n",
    "        mse = np.mean((actual_values - prediction) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def calculate_overall_metric(data_below, data_above, metric_function):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_metric =  (p_data_below * metric_function(data_below) \n",
    "                     + p_data_above * metric_function(data_above))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "def determine_best_split(data, potential_splits, ml_task):\n",
    "    \n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                current_overall_metric = calculate_overall_metric(data_below, data_above, metric_function=calculate_mse)\n",
    "            \n",
    "            # classification\n",
    "            else:\n",
    "                current_overall_metric = calculate_overall_metric(data_below, data_above, metric_function=calculate_entropy)\n",
    "\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                \n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "# 1.5 Split data\n",
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above\n",
    "\n",
    "\n",
    "# 2. Decision Tree Algorithm\n",
    "# 2.1 Helper Function\n",
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types\n",
    "\n",
    "\n",
    "# 2.2 Algorithm\n",
    "def decision_tree_algorithm(df, ml_task, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        leaf = create_leaf(data, ml_task)\n",
    "        return leaf\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits, ml_task)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # check for empty data\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            leaf = create_leaf(data, ml_task)\n",
    "            return leaf\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, ml_task, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, ml_task, counter, min_samples, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree\n",
    "\n",
    "\n",
    "# 3. Make predictions\n",
    "# 3.1 One example\n",
    "def predict_example(example, tree):\n",
    "    \n",
    "    # tree is just a root node\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)\n",
    "\n",
    "    \n",
    "# 3.2 All examples of a dataframe\n",
    "def make_predictions(df, tree):\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        predictions = df.apply(predict_example, args=(tree,), axis=1)\n",
    "    else:\n",
    "        # \"df.apply()\"\" with empty dataframe returns an empty dataframe,\n",
    "        # but \"predictions\" should be a series instead\n",
    "        predictions = pd.Series()\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# 3.3 Accuracy\n",
    "def calculate_accuracy(df, tree):\n",
    "    predictions = make_predictions(df, tree)\n",
    "    predictions_correct = predictions == df.label\n",
    "    accuracy = predictions_correct.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCnVNebwTsZx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvOZl72CTw8O"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sz-P4MxJUAaZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_data(n, specific_outliers=[], n_random_outliers=None):\n",
    "    \n",
    "    # create data\n",
    "    data = np.random.random(size=(n, 2)) * 10\n",
    "    data = data.round(decimals=1)\n",
    "    df = pd.DataFrame(data, columns=[\"x\", \"y\"])\n",
    "    df[\"label\"] = df.x <= 5\n",
    "\n",
    "    # add specific outlier data points\n",
    "    for outlier_coordinates in specific_outliers:\n",
    "        df = df.append({\"x\": outlier_coordinates[0],\n",
    "                        \"y\": outlier_coordinates[1],\n",
    "                        \"label\": True}, \n",
    "                       ignore_index=True)\n",
    "\n",
    "    ## add random outlier data points\n",
    "    if n_random_outliers:\n",
    "        outlier_x_values =  (6 - 5) * np.random.random(size=n_random_outliers) + 5  # value between 5 and 6\n",
    "        outlier_y_values = np.random.random(size=n_random_outliers) * 10\n",
    "\n",
    "        df_outliers = pd.DataFrame({\"x\": outlier_x_values.round(decimals=2),\n",
    "                                    \"y\": outlier_y_values.round(decimals=2),\n",
    "                                    \"label\": [True] * n_random_outliers})\n",
    "\n",
    "        df = df.append(df_outliers, ignore_index=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvNj5morUEJt"
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(tree, x_min, x_max, y_min, y_max):\n",
    "    color_keys = {True: \"orange\", False: \"blue\"}\n",
    "    \n",
    "    # recursive part\n",
    "    if isinstance(tree, dict):\n",
    "        question = list(tree.keys())[0]\n",
    "        yes_answer, no_answer = tree[question]\n",
    "        feature, _, value = question.split()\n",
    "    \n",
    "        if feature == \"x\":\n",
    "            plot_decision_boundaries(yes_answer, x_min, float(value), y_min, y_max)\n",
    "            plot_decision_boundaries(no_answer, float(value), x_max, y_min, y_max)\n",
    "        else:\n",
    "            plot_decision_boundaries(yes_answer, x_min, x_max, y_min, float(value))\n",
    "            plot_decision_boundaries(no_answer, x_min, x_max, float(value), y_max)\n",
    "        \n",
    "    # \"tree\" is a leaf\n",
    "    else:\n",
    "        plt.fill_between(x=[x_min, x_max], y1=y_min, y2=y_max, alpha=0.2, color=color_keys[tree])\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDuUsfH9UMEK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_plot(df, tree=None, title=None):\n",
    "    \n",
    "    sns.lmplot(data=df, x=\"x\", y=\"y\", hue=\"label\", \n",
    "               fit_reg=False, height=4, aspect=1.5, legend=False)\n",
    "    plt.title(title)\n",
    "    \n",
    "    if tree or tree == False: # root of the tree might just be a leave with \"False\"\n",
    "        x_min, x_max = round(df.x.min()), round(df.x.max())\n",
    "        y_min, y_max = round(df.y.min()), round(df.y.max())\n",
    "\n",
    "        plot_decision_boundaries(tree, x_min, x_max, y_min, y_max)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "id": "VU-NtQOZUOfJ",
    "outputId": "cfaf6407-fe2e-4583-d10b-d3eb79105965"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df_train = generate_data(n=300, specific_outliers=[(5.4, 8.4)])\n",
    "tree = decision_tree_algorithm(df_train, ml_task=\"classification\", max_depth=10)\n",
    "create_plot(df_train, tree, title=\"Training Data\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agsxw0pRnlGR"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "13-P4DS Classification 2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
